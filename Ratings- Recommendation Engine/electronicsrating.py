# -*- coding: utf-8 -*-
"""ElectronicsRating.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-ZeGLDkc80q6AeOtcTvUl3YNYuSt-Bvx

Problem Statement -

Build your own recommendation system for products on an e-commerce website like Amazon.com.



Dataset columns - first three columns are userId, productId, and ratings and the fourth column is timestamp discard the timestamp column as in this case you may not need to use it.

Source - Amazon Reviews data (http://jmcauley.ucsd.edu/data/amazon/)  The repository has several datasets. For this case study, we are using the Electronics dataset


Read and explore the given dataset.  ( Rename column/add headers, plot histograms, find data characteristics)
Take a subset of the dataset to make it less sparse/ denser. ( For example, keep the users only who has given 50 or more number of ratings )
Split the data randomly into train and test dataset. ( For example, split it in 70/30 ratio)
Build Popularity Recommender model.
Build Collaborative Filtering model.
Evaluate both the models. ( Once the model is trained on the training data, it can be used to compute the error (like RMSE) on predictions made on the test data.) You can also use a different method to evaluate the models.
Get top - K ( K = 5) recommendations. Since our goal is to recommend new products to each user based on his/her habits, we will recommend 5 new products.
Summarise  insights.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import warnings
warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My\ Drive/Colab\ Notebooks/

!pwd

#Read file from google drive

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

df = pd.read_csv('ratings_Electronics.csv', names  = ['userId','productId','ratings','timestamp'])

df.drop(columns=['timestamp'], inplace = True)

df.head(3)

df.info()

# Subsetting the data frame for users having rating more then 50

r1 = pd.DataFrame(df.groupby('userId')['ratings'].count())
users_rat = pd.DataFrame(r1[(r1['ratings'] > 50)].sort_values(by = 'ratings', ascending = False))
ratings_df = pd.merge(users_rat , df[['userId','ratings','productId']], on = 'userId')
ratings_df.drop(columns=['ratings_x'], inplace = True)
ratings_df.rename(columns={'ratings_y':'ratings'},inplace = True)

ratings_df.head(5)

"""# Determine the ratings distribution using histogram:

- Maximum number of 5 ratings provided in the dataset
"""

sns.distplot(ratings_df['ratings'],hist = True, kde = 'False')

# Find the Null Values if any in the Dataset:

ratings_df.isnull().sum()

"""# Building Popularity Based Recommendation :

- Most rated Products in the dataset.

- Simple Popularity Based Recommendation
"""

from sklearn.model_selection import train_test_split
import Evaluation as Evaluation

# Simple recommender engine on popularity based

ratings_df_grouped = ratings_df.groupby(['productId']).agg({'ratings': 'count'}).reset_index()
grouped_sum = ratings_df_grouped['ratings'].sum()
print(grouped_sum)
ratings_df_grouped['percentage']  = ratings_df['ratings'].div(grouped_sum)*100
ratings_df_grouped.sort_values(['ratings', 'productId'], ascending = [0,1], inplace= True)

#top 15 products.
ratings_df_grouped.head(15)

# Creating Recommendation engine Rank and Score for User ID

trainset,testset = train_test_split(ratings_df, test_size = 0.2, random_state = 1234)

train_data_grouped = trainset.groupby(['productId']).agg({'userId': 'count'}).reset_index()
train_data_grouped.rename(columns = {'userId': 'score'},inplace=True)
train_data_sort = train_data_grouped.sort_values(['score', 'productId'], ascending = [0,1])
train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')
popularity_recommendations = train_data_sort.head(10)

popularity_recommendations

#Use the popularity based recommender system model to make recommendations

def recommend(userId):
        user_recommendations = popularity_recommendations

        #Add user_id column for which the recommendations are being generated
        user_recommendations['userId'] = userId

        #Bring user_id column to the front
        cols = user_recommendations.columns.tolist()
        cols = cols[-1:] + cols[:-1]
        user_recommendations = user_recommendations[cols]

        return user_recommendations.iloc[:,0:3]

# Recommending to userid
recommend(10)

"""# Summary:
- In the above steps we created the Popularity Based Model using Rank and recommend function created above.

- We are recommending top 10 products to any new users which on the basis of the score and rank provided.

- score is calculated on the basis of users provided max ratings to product ids.

# Collaborative Filtering:

- EDA on DATA

- Using Surprise Package
"""

ratings_df.info()

ratings_df.head(5)

# find the most rated productid

ratings_df.groupby('productId')['ratings'].value_counts().sort_values(ascending = False).head(10)

# User with max number of ratings.

ratings_df.groupby('userId')['ratings'].value_counts().sort_values(ascending = False).head(10)

from surprise import Reader,Dataset
from surprise.model_selection import train_test_split

ratings_df.info()

ratings_df.ratings = ratings_df.ratings.astype(str)

reader = Reader(rating_scale=(1,5))

# columns passed below must always be in order uid,itemid,ratings.
data = Dataset.load_from_df(ratings_df[['userId','productId','ratings']],reader = reader)

data

# Divide into 70/30 ratio

trainset,testset = train_test_split(data,test_size=0.3,random_state= 1234)

trainset.to_raw_uid(0)
trainset.to_raw_iid(2)

from surprise import KNNWithMeans
from surprise import accuracy
from surprise import Prediction

# Creating user user based collaborative filtering model

model = KNNWithMeans(k = 51, sim_options= {'name':'cosine', 'user_based':True})

model.fit(trainset)

test_preds = model.test(testset)

test_preds[0:3]

accuracy.rmse(test_preds)

# converting predictions back into Dataframe

Predictions = pd.DataFrame(test_preds)
Predictions["was_impossible"] = [x["was_impossible"] for x in Predictions["details"]]

Predictions[Predictions.was_impossible == False]

# Make Prediction for single User

model.predict(uid  = 'A22MANL4US4RMY', iid = 'B00FF8ZRR8')

# Creating top 5 recommendations

"""# Using build_anti_testset
- Return a list of ratings that can be used as a testset in the test() method.

- The ratings are all the ratings that are not in the trainset, i.e. all the ratings rui where the user u is known, the item i is known, but the rating rui is not in the trainset.
"""

s
